{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b45c0e",
   "metadata": {},
   "source": [
    "# Testing for LLM APIs\n",
    "\n",
    "Black-box\n",
    "- gpt 3.5\n",
    "- gemini 2.5 Flash\n",
    "- Claude Sonnet 4.5\n",
    "\n",
    "White-box\n",
    "- Llama 3.1 8B\n",
    "- Vicuna 13B\n",
    "- DeepSeek 3.1\n",
    "- Mistral 7B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4cca4",
   "metadata": {},
   "source": [
    "# Black-Box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f47e3",
   "metadata": {},
   "source": [
    "## GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a2c0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_info', 'api_key_info', 'params'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read config\n",
    "config_path = \"../../model_configs/gpt3.5_config.json\"\n",
    "\n",
    "# Read JSON\n",
    "with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(config.keys())   # Check Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c44fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd/TSF/grow/src/models\n",
      "=== PROMPT ===\n",
      "What is 1+2? Just answer with an number.\n",
      "\n",
      "=== OUTPUT ===\n",
      "3\n",
      "\n",
      "(latency: 1.18s)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/ssd/TSF/grow')\n",
    "\n",
    "import time\n",
    "from src.utils import load_json\n",
    "from src.models import GPT \n",
    "\n",
    "CFG = \"../../model_configs/gpt3.5_config.json\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = load_json(CFG)\n",
    "    llm = GPT(cfg)\n",
    "\n",
    "    prompt = \"What is 1+2? Just answer with an number.\"\n",
    "    t0 = time.time()\n",
    "    out = llm.query(prompt)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    print(\"=== PROMPT ===\")\n",
    "    print(prompt)\n",
    "    print(\"\\n=== OUTPUT ===\")\n",
    "    print(out)\n",
    "    print(f\"\\n(latency: {dt:.2f}s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c521d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROMPT ===\n",
      "What is 1+2? Just answer with an number.\n",
      "\n",
      "=== OUTPUT ===\n",
      "3\n",
      "\n",
      "(latency: 2.86s)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/ssd/TSF/grow')\n",
    "\n",
    "import time\n",
    "from src.utils import load_json\n",
    "from src.models import GPT5\n",
    "\n",
    "CFG = \"../../model_configs/gpt5_config.json\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = load_json(CFG)\n",
    "    llm = GPT5(cfg)\n",
    "\n",
    "    prompt = \"What is 1+2? Just answer with an number.\"\n",
    "    t0 = time.time()\n",
    "    out = llm.query(prompt)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    print(\"=== PROMPT ===\")\n",
    "    print(prompt)\n",
    "    print(\"\\n=== OUTPUT ===\")\n",
    "    print(out)\n",
    "    print(f\"\\n(latency: {dt:.2f}s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f9037",
   "metadata": {},
   "source": [
    "## Gemini 2.5 Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a0e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd/TSF/grow/src/models\n",
      "=== PROMPT ===\n",
      " What is 1+2? Just answer with a number.\n",
      "\n",
      "=== OUTPUT ===\n",
      " 3\n",
      "\n",
      "(latency: 1.25s)\n"
     ]
    }
   ],
   "source": [
    "import sys, time\n",
    "sys.path.append('/mnt/ssd/TSF/grow') \n",
    "\n",
    "from src.utils import load_json\n",
    "from src.models import create_model \n",
    "\n",
    "CFG = \"../../model_configs/gemini_config.json\"\n",
    "\n",
    "cfg = load_json(CFG)\n",
    "llm = create_model(cfg)\n",
    "\n",
    "prompt = \"What is 1+2? Just answer with a number.\"\n",
    "t0 = time.time()\n",
    "out = llm.query(prompt)\n",
    "dt = time.time() - t0\n",
    "\n",
    "print(\"=== PROMPT ===\\n\", prompt)\n",
    "print(\"\\n=== OUTPUT ===\\n\", out)\n",
    "print(f\"\\n(latency: {dt:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2574a696",
   "metadata": {},
   "source": [
    "## Claude 3.7 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a12e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd/TSF/grow/src/models\n",
      "=== PROMPT ===\n",
      " What is 1+2? Just answer with a number.\n",
      "\n",
      "=== OUTPUT ===\n",
      " 3\n",
      "\n",
      "(latency: 1.67s)\n"
     ]
    }
   ],
   "source": [
    "import sys, time\n",
    "sys.path.append('/mnt/ssd/TSF/grow')\n",
    "\n",
    "from src.utils import load_json\n",
    "from src.models import create_model \n",
    "\n",
    "CFG = \"../../model_configs/claude_config.json\"\n",
    "\n",
    "cfg = load_json(CFG)\n",
    "llm = create_model(cfg) \n",
    "\n",
    "prompt = \"What is 1+2? Just answer with a number.\"\n",
    "t0 = time.time()\n",
    "out = llm.query(prompt)\n",
    "dt = time.time() - t0\n",
    "\n",
    "print(\"=== PROMPT ===\\n\", prompt)\n",
    "print(\"\\n=== OUTPUT ===\\n\", out)\n",
    "print(f\"\\n(latency: {dt:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a1bed",
   "metadata": {},
   "source": [
    "# White Box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a820e",
   "metadata": {},
   "source": [
    "## Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849dc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd/TSF/grow/src/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROMPT ===\n",
      " What is 1+2? Just answer with a number.\n",
      "\n",
      "=== OUTPUT ===\n",
      " 3\n",
      "\n",
      "(latency: 0.95s)\n"
     ]
    }
   ],
   "source": [
    "import sys, time\n",
    "sys.path.append('/mnt/ssd/TSF/grow')  \n",
    "from src.utils import load_json\n",
    "from src.models import create_model   \n",
    "CFG = \"../../model_configs/llama_config.json\"\n",
    "\n",
    "cfg = load_json(CFG)\n",
    "llm = create_model(cfg)  \n",
    "\n",
    "prompt = \"What is 1+2? Just answer with a number.\"\n",
    "t0 = time.time()\n",
    "out = llm.query(prompt)\n",
    "dt = time.time() - t0\n",
    "\n",
    "print(\"=== PROMPT ===\\n\", prompt)\n",
    "print(\"\\n=== OUTPUT ===\\n\", out)\n",
    "print(f\"\\n(latency: {dt:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1ada7",
   "metadata": {},
   "source": [
    "## Vicuna 13B v 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a5c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd/TSF/grow/src/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 22.17it/s]\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROMPT ===\n",
      " What is 1+2? Just answer with a number.\n",
      "\n",
      "=== OUTPUT ===\n",
      " 1+2 is equal to 3.\n",
      "\n",
      "(latency: 1.38s)\n"
     ]
    }
   ],
   "source": [
    "import sys, time\n",
    "sys.path.append('/mnt/ssd/TSF/grow') \n",
    "\n",
    "from src.utils import load_json\n",
    "from src.models import create_model  \n",
    "\n",
    "CFG = \"../../model_configs/vicuna_config.json\"\n",
    "\n",
    "cfg = load_json(CFG)\n",
    "llm = create_model(cfg)  \n",
    "\n",
    "prompt = \"What is 1+2? Just answer with a number.\"\n",
    "t0 = time.time()\n",
    "out = llm.query(prompt)\n",
    "dt = time.time() - t0\n",
    "\n",
    "print(\"=== PROMPT ===\\n\", prompt)\n",
    "print(\"\\n=== OUTPUT ===\\n\", out)\n",
    "print(f\"\\n(latency: {dt:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20042f",
   "metadata": {},
   "source": [
    "## Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05678b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alexhur3535/anaconda3/envs/grow/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd/TSF/grow/src/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.79it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROMPT ===\n",
      " What is 1+2? Just answer with a number.\n",
      "\n",
      "=== OUTPUT ===\n",
      " 3\n",
      "\n",
      "(latency: 6.72s)\n"
     ]
    }
   ],
   "source": [
    "import sys, time\n",
    "sys.path.append('/mnt/ssd/TSF/grow')  \n",
    "\n",
    "from src.utils import load_json\n",
    "from src.models import create_model  \n",
    "\n",
    "CFG = \"../../model_configs/mistral_config.json\"\n",
    "\n",
    "cfg = load_json(CFG)\n",
    "llm = create_model(cfg)  \n",
    "\n",
    "prompt = \"What is 1+2? Just answer with a number.\"\n",
    "t0 = time.time()\n",
    "out = llm.query(prompt)\n",
    "dt = time.time() - t0\n",
    "\n",
    "print(\"=== PROMPT ===\\n\", prompt)\n",
    "print(\"\\n=== OUTPUT ===\\n\", out)\n",
    "print(f\"\\n(latency: {dt:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecfd77d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
