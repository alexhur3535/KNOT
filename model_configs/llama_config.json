{
  "model_info": { 
    "provider":"Llama",
    "name": "meta-llama/Meta-Llama-3.1-8B-Instruct"  
},
  "api_key_info": { 
    "api_keys": ["YOUR_KEY_HERE"], 
    "api_key_use": 0 
},
"params":{
    "temperature":0.01,
    "seed":100,
    "gpus":[],
    "max_output_tokens":400
}
}
